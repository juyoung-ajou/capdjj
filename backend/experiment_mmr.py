# backend/experiment_mmr_realistic.py

import numpy as np
from langchain_huggingface import HuggingFaceEmbeddings
from sklearn.metrics.pairwise import cosine_similarity

# ==============================================================================
# ğŸ“„ [ë°ì´í„°ì…‹] í˜„ì‹¤ì ì¸ ì‹œë‚˜ë¦¬ì˜¤
# - ì¢€ë¹„(ì¤‘ë³µ): 12ê°œ (ìƒìœ„ê¶Œ ë„ë°°ìš©)
# - í•¨ì •(ìœ ì‚¬): 5ê°œ (í—·ê°ˆë¦¬ê²Œ ë§Œë“¤ê¸°)
# - ì •ë‹µ: 1ê°œ (êµ¬ì²´ì ì¸ ë‚ ì§œ)
# ==============================================================================
documents = []

# [ê·¸ë£¹ A] ì¢€ë¹„ ë¬¸ì„œ (12ê°œ) - "ê¸°ê°„ ì•ˆë‚´"ë¼ê³  ì œëª©ë§Œ ìˆê³  ë‚ ì§œëŠ” ì—†ëŠ” ê¸€ë“¤
# (ë²¡í„° ìœ ì‚¬ë„ê°€ ë†’ì•„ì„œ 1í˜ì´ì§€ë¥¼ ì°¨ì§€í•¨)
for i in range(1, 13):
    documents.append(f"[ê³µì§€] 2024-1í•™ê¸° ìˆ˜ê°•ì‹ ì²­ ì¼ì • ë° ìœ ì˜ì‚¬í•­ ì•ˆë‚´ ({i})")

# [ê·¸ë£¹ B] í•¨ì • ë¬¸ì„œ (5ê°œ) - "ê¸°ê°„"ì€ ë§ëŠ”ë° ë‹¤ë¥¸ ê¸°ê°„ (ì¥í•™ê¸ˆ, ê¸°ìˆ™ì‚¬ ë“±)
documents.append("2024í•™ë…„ë„ 1í•™ê¸° êµ­ê°€ì¥í•™ê¸ˆ ì‹ ì²­ ê¸°ê°„ ì•ˆë‚´")
documents.append("2024-1í•™ê¸° ìƒí™œê´€(ê¸°ìˆ™ì‚¬) ì…ì‚¬ ê¸°ê°„ ê³µì§€")
documents.append("2024í•™ë…„ë„ ë“±ë¡ê¸ˆ ë‚©ë¶€ ê¸°ê°„ ì•ˆë‚´")
documents.append("1í•™ê¸° ìˆ˜ê°• ì •ì • ê¸°ê°„ ë° ì·¨ì†Œ ê¸°ê°„ ì•ˆë‚´")
documents.append("ê³„ì ˆí•™ê¸° ìˆ˜ê°•ì‹ ì²­ ê¸°ê°„ì€ ë³„ë„ ê³µì§€ ì˜ˆì •ì…ë‹ˆë‹¤.")

# [ê·¸ë£¹ C] ì§„ì§œ ì •ë‹µ (1ê°œ) - ì‚¬ìš©ìê°€ ì°¾ëŠ” 'êµ¬ì²´ì  ë‚ ì§œ'
target_doc = ">> [í•„ë…] ì‹¤ì œ ìˆ˜ê°•ì‹ ì²­ ê¸°ê°„: 2ì›” 13ì¼(í™”) 10:00 ~ 2ì›” 15ì¼(ëª©) 17:00 <<"
documents.append(target_doc)
target_idx = len(documents) - 1

# [ê·¸ë£¹ D] ë°°ê²½ ë¬¸ì„œ
documents.append("ì•„ì£¼ëŒ€í•™êµ í•™ì‹ ë©”ë‰´ ì•ˆë‚´")
documents.append("ë„ì„œê´€ ì´ìš© ì‹œê°„ ë³€ê²½ ì•ˆë‚´")

# ì§ˆë¬¸
query = "2024ë…„ 1í•™ê¸° ìˆ˜ê°•ì‹ ì²­ ê¸°ê°„ ë©°ì¹ ë¶€í„°ì•¼?"

# ==============================================================================
# âš™ï¸ MMR ì•Œê³ ë¦¬ì¦˜
# ==============================================================================
def mmr_sort(doc_vectors, query_vector, lambda_mult=0.5, top_k=10):
    # lambda_mult=0.5 : ìœ ì‚¬ë„ì™€ ë‹¤ì–‘ì„±ì„ ë°˜ë°˜ì”© ê³ ë ¤ (ê°€ì¥ ì¼ë°˜ì ì¸ ì„¸íŒ…)
    sims_to_query = cosine_similarity([query_vector], doc_vectors)[0]
    
    selected_indices = []
    candidate_indices = list(range(len(doc_vectors)))
    
    for _ in range(top_k):
        best_score = -float("inf")
        best_idx = -1
        
        for idx in candidate_indices:
            relevance = sims_to_query[idx]
            
            if selected_indices:
                sims_to_selected = cosine_similarity(
                    [doc_vectors[idx]], 
                    [doc_vectors[i] for i in selected_indices]
                )[0]
                redundancy = np.max(sims_to_selected)
            else:
                redundancy = 0
            
            mmr_score = (lambda_mult * relevance) - ((1 - lambda_mult) * redundancy)
            
            if mmr_score > best_score:
                best_score = mmr_score
                best_idx = idx
        
        selected_indices.append(best_idx)
        candidate_indices.remove(best_idx)
        
    return selected_indices

# ==============================================================================
# ğŸ§ª ì‹¤í—˜ ì‹¤í–‰
# ==============================================================================
def run_experiment():
    print("âš¡ [í˜„ì‹¤ì ì¸ ì‹¤í—˜] Standard vs MMR : ì •ë³´ì˜ í™ìˆ˜ ì†ì—ì„œ ì •ë‹µ ì°¾ê¸°")
    print(f"ğŸ“„ ë°ì´í„°: ì´ {len(documents)}ê°œ (ì¤‘ë³µ 12ê°œ, í•¨ì • 5ê°œ, ì •ë‹µ 1ê°œ)")
    print("   -> ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")
    doc_vectors = embeddings.embed_documents(documents)
    query_vector = embeddings.embed_query(query)
    
    print("-" * 80)
    print(f"â“ ì§ˆë¬¸: '{query}'")
    print("-" * 80)
    
    # --- [1] Standard Search ---
    # ë‹¨ìˆœíˆ ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ 20ê°œ í™•ì¸
    sim_scores = cosine_similarity([query_vector], doc_vectors)[0]
    std_indices = np.argsort(sim_scores)[::-1]
    
    std_rank = np.where(std_indices == target_idx)[0][0] + 1
    
    print(f"\nğŸ¢ [Before] Standard Search")
    print(f"   - ì •ë‹µ ìœ„ì¹˜: {std_rank}ìœ„")
    print("     (ì„¤ëª…: ìœ ì‚¬í•œ ê³µì§€ì‚¬í•­ë“¤ì— ë°€ë ¤ì„œ 2í˜ì´ì§€ì¯¤ ë’¤ì— ë‚˜ì˜´)")
    
    # ìƒìœ„ 3ê°œë§Œ ë³´ì—¬ì£¼ê¸°
    print("   - ìƒìœ„ 3ê°œ ê²°ê³¼:")
    for i in range(3):
        print(f"     {i+1}ìœ„: {documents[std_indices[i]]}")
    
    mrr_std = 1 / std_rank

    # --- [2] MMR Search ---
    # lambda=0.5 (ì ì ˆí•œ ê· í˜•)
    mmr_indices = mmr_sort(doc_vectors, query_vector, lambda_mult=0.5, top_k=10)
    
    try:
        mmr_rank = mmr_indices.index(target_idx) + 1
    except ValueError:
        mmr_rank = -1 
        
    print(f"\nğŸš€ [After] MMR Search")
    print(f"   - ì •ë‹µ ìœ„ì¹˜: {mmr_rank}ìœ„")
    print("     (ì„¤ëª…: ì¤‘ë³µëœ ê³µì§€ë“¤ì„ ê±´ë„ˆë›°ê³  ìƒìœ„ê¶Œ(Top 5) ì•ˆìœ¼ë¡œ ì§„ì…)")

    print("   - ìƒìœ„ 3ê°œ ê²°ê³¼:")
    for i, idx in enumerate(mmr_indices[:3]):
        mark = "ğŸ‘ˆ âœ… ì •ë‹µ!" if idx == target_idx else ""
        print(f"     {i+1}ìœ„: {documents[idx]} {mark}")

    mrr_mmr = 1 / mmr_rank if mmr_rank != -1 else 0

    # ìµœì¢… ë¹„êµ
    print("-" * 80)
    print(f"ğŸ“Š ìµœì¢… ì„±ì í‘œ (í˜„ì‹¤ì ì¸ ê°œì„ í­)")
    print(f"   [Standard] MRR: {mrr_std:.4f} (ì°¾ê¸° í˜ë“¦)")
    print(f"   [MMR]      MRR: {mrr_mmr:.4f} (ì¾Œì í•¨)")
    
    improvement = ((mrr_mmr - mrr_std) / mrr_std) * 100
    print(f"   ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒë¥ : {improvement:.1f}% ì¦ê°€")
    print("=" * 80)

if __name__ == "__main__":
    run_experiment()